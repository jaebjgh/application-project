{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API to stream Tweets\n",
    "\n",
    "In diesem Notebook wird der Einsatz der Twitter API für das Streaming von Tweets anhand bestimmter Filterwörter erläutert.  \n",
    "Für die Twitter API gibt es ein Python Paket mit dem Namen [Tweepy](https://www.tweepy.org/), das die Funktionen der Twitter API für einen kompakteren Zugriff in der Programmiersprache Python ermöglicht.  \n",
    "Voraussetzung für die Nutzung der API ist ein Twitter Developer Account, mit dem der Zugriff auf die API mittels Authentifizierungstoken geschehen kann.  \n",
    "Um Tweets streamen zu können, muss eine Klasse erstellt werden, die von der [tweepy.Stream](https://docs.tweepy.org/en/v4.4.0/streaming.html) Klasse erbt und dadurch eine Methode onData() erben kann. Der onData()-Methode wird der empfangene Tweet als Parameter übergeben und kann dann entsprechend verarbeitet werden, in unserem Fall in der MongoDB gespeichert werden.  \n",
    "Im folgenden wird Schrittweise erläutert, wie wir vorgegangen sind.\n",
    "\n",
    "Zunächst laden wir die benötigten Pakete für Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "import pandas as pd \n",
    "import tweepy\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der .env-Datei, in der die Authentifizierungstoken gespeichert sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../../.env') # .env file in 'code' dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der Datei mit den Bezirken und Platznamen\n",
    "\n",
    "In der CSV-Datei stehen alle Bezirke und Platznamen, die wir als Filterwörter unserem Stream übergeben, die Bezirke und Plätze wurden aus dem [OpenData Portal](https://transparenz.hamburg.de/) der Stadt Hamburg heruntergeladen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = pd.read_csv('names_to_track.csv')['0'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufsetzen der MongoDB\n",
    "\n",
    "Als nächstes wird eine Instanz der MongoDB Datenbank definiert. In unserem Falle heißt die Datenbank 'Webgefluester' und die Collection, in der wir alle Tweets ablegen möchten heißt 'streaming_tweets'. Dabei werden entsprechende Instanzen der Datenbank und der Collection erzeugt, wenn sie noch nicht vorhanden sein sollten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MongoDB\n",
    "client = pymongo.MongoClient('localhost:27017')\n",
    "db = client[\"webgefluester\"]\n",
    "collection = db['streaming_tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erben von der tweepy.Stream Klasse\n",
    "\n",
    "Um die Streaming API nutzen zu können und eintreffende Tweets analysieren und speichern zu können, wird von der tweepy.Stream Klasse geerbt und die Methode onData() implementiert. Wenn ein Tweet auf Twitter dem Filter entspricht, wird die Methode onData() aufgerufen und der Tweet übergeben.  \n",
    "Die Methode lädt den Tweet dann im JSON-Format und fügt einen neuen Schlüssel mit dem Namen '_id' hinzu, der dem Wert des Schlüssels 'id' entspricht. Dadurch speichert die MongoDB die Tweets unter derselben ID ab, wie sie bei Twitter abgespeichert werden und es werden keine Tweets doppelt abgespeichert.  \n",
    "Als nächstes wird der Tweet in die zuvor definierte Collection eingefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from tweepy.Stream class to change the on_data function\n",
    "class MyStream(tweepy.Stream):\n",
    "\n",
    "    #this function gets called when a tweet meets the search criteria\n",
    "    def on_data(self, data):\n",
    "        tweet = json.loads(data.decode('utf-8'))\n",
    "        tweet['_id'] = tweet['id']\n",
    "        collection.insert_one(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starten des Streams\n",
    "\n",
    "Um den Stream starten zu können, reicht es, ein Objekt der gerade erstellten Klasse MyStream mit den benötigten Authentifizierungstoken aus der .env-Datei zu erstellen und die Methode filter() mit den gewünschten Filterwörtern aufzurufen.  \n",
    "Um ein Abbrechen des Streams zu vermeiden, wird eine zusätzliche Fehlerbehandlung mittels try-Except Statements eingebaut, die nur bei einer Unterbrechung mittels des Keyboards den Prozess abbricht und ansonsten immer neu startet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_stream():\n",
    "    while True:\n",
    "        try:\n",
    "            #setup stream authentication\n",
    "            stream = MyStream(os.getenv(\"CONSUMER_KEY\"),\n",
    "                        os.getenv(\"CONSUMER_SECRET\"),\n",
    "                        os.getenv(\"ACCESS_TOKEN\"),\n",
    "                        os.getenv(\"ACCESS_TOKEN_SECRET\"))\n",
    "            stream.filter(track=list(to_track), languages = ['de'])\n",
    "        except KeyboardInterrupt: \n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "start_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets aus Datenbank ziehen\n",
    "\n",
    "Die gesammelten Tweets können dann einfach als CSV-Datei aus der Datenbank heruntergeladen werden und in der tweet_processing.py Datei eingelesen, vorverarbeitet und analysiert werden."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ddef63aae287916d01c4ac74d022f230b4944473812a2e17aafbf06037720e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ap': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
